Q1. What are the three stages to build the hypotheses or model in machine learning?
Ans: Below are the three stages to build a hypotheses...
Stage 1) Model building
Stage 2) Model testing
Stage 3) Applying the model

Q2. What is the standard approach to supervised learning?
Ans: The standard approach for supervised learning is to split the set of example into the training set and the test set.

Q3. What is ‘Training set’ and ‘Test set’?
Ans: In machine learning, a set of data is used to discover the potentially predictive relationship. this set of data is known as ‘Training Set’. Training set is an examples given to the learner.
Test set is used to test the accuracy of the hypotheses generated by the learner, and it is the set of example held back from the learner. 
Training set are distinct from Test set.

Q4. What is the general principle of an ensemble method and what is bagging and boosting in ensemble method?
Ans: The general principle of an ensemble method is to combine the predictions of several models built with a given learning algorithm in order to improve robustness over a single model.  
Bagging:  Bootstrap aggregating, often abbreviated as bagging, involves having each model in the ensemble vote with equal weight. In order to promote model variance, bagging trains each model in the ensemble using a randomly drawn subset of the training set. It's a method in ensemble for improving unstable estimation or classification schemes.  
Boosting: Boosting involves incrementally building an ensemble by training each new model instance to emphasize the training instances that previous models mis-classified. Boosting method are used sequentially to reduce the bias of the combined model.  
Boosting and Bagging both can reduce errors by reducing the variance term.

Q5. How can you avoid overfitting ?
Ans: By using a lot of data overfitting can be avoided, overfitting happens relatively as you have a small dataset, and you try to learn from it. But if you have a small database and you are forced to come with a model based on that. Cross validation is a method can be used in case of overfitting, in this method the dataset splits into two section, testing and training datasets, the testing dataset will only test the model while, in training dataset, the datapoints will come up with the model.
     
